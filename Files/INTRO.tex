\chapter*{Introduction}

During their undergraduate courses in quantum mechanics, students often encounter the \emph{particle in a box}. It is the simplest and most educational model to illustrate the concepts and inner workings of quantum mechanics, without the need for complex mathematics. In this hypothetical model, a non-classical and non-relativistic particle is stuck in an infinite, one-dimensional \emph{potential-well} $V(x)$, which is zero in a certain domain $x \in [0,L]$, and infinite everywhere else. \emph{Non-classical} and \emph{non-relativistic} means that the Schrödinger equation is used to obtain a solution of the system. The particle in a box model teaches two important concepts: (1) the particle is described by a \emph{wave function}  $\Psi(x)$, with the observable $\left\lvert \Psi (x) \right\rvert^2$ measuring the probability of finding the particle at a given position $x$, and (2) the energy levels are \emph{quantized}. If the lecturer is feeling particularly adventurous, they might also tackle 3-dimensional systems such as the hydrogen atom. While the particle in a box can be described by simple sine and cosine functions, the mathematics are much more complex in this case. The solutions to the Schrödinger equation of the hydrogen atom atoms are known as \emph{atomic orbitals}. Atomic orbitals are mathematical functions that are composed of a radial part, which changes with the distance $r$ from the nucleus, and an angular part which determines the shape of the orbital (s,p,d,...). 

Hydrogen and hydrogen-like atoms, i.e. atoms with a single electron (He$^+$, Li$^{2+}$), are among the only types of quantum systems for which the Schrödinger equation can be solved analytically. Even for relatively simple systems like H$_2$, no closed form solution exists. This is the quantum equivalent of the $n$-body problem: the systems can only be computed numerically to a given accuracy. While numerical approaches are not problematic \emph{per se}, the time-to-solution rapidly increases with the number of particles and mesh size of the grid on which the equations are evaluated, quickly exhausting computational resources.    

One way to reduce the computational effort is to introduce approximations to the Schrödinger equation. The Born-Oppenheimer approximation  is undoubtedly one of the best known approximations in quantum chemistry. It decouples the nuclear from the electronic degrees of freedom and reduces the problem into two smaller steps. Solving the electronic Schrödinger equation gives a potential energy surface for the nuclei to move on, and their trajectories are easily computed. The problem therefore reduces to computing the electronic wave function which in and of itself still remains a major challenge, and further approximations are necessary. \emph{Electronic structure methods} differ by their way of modeling electron-electron interactions, also known as \emph{electron correlation}. In the Hartree-Fock approximation, each electron sees the average potential of all the other electrons. While HF accounts for 99\% of the total electronic energy, the remaining 1\%, which is formerly defined as the correlation energy, is often crucial for computing chemical properties accurately. Building up on the HF wave function, correlated methods have been developed that allow systematic convergence towards the exact wave function by adding higher order terms, such as configuration interaction (CI), coupled cluster (CC) or M{\o}ller Plesset perturbation theory (MPPT). 

Very good accuracy for molecular properties can be already obtained by adding only a few correction terms. However, methods such as second order M{\o}ller Plesset (MP2) or coupled cluster with singles and doubles (CCSD) are still computationally expensive, and scale with the fifth and sixth power of the molecular size, and are generally not applicable for large systems. The steep scaling of correlated methods is not chemically intuitive. Consider for example functional groups. Functional groups are important conceptual tools in organic chemistry to describe molecular properties and reaction pathways, and work under the assumption that the same substituents undergo similar reactions with little influence from the rest of the molecule. A system can be divided into several "domains", which influence each other less and less the greater their separation is. 

\emph{Local correlation methods} exploit the nearsightedness of electrons to drastically lower the scaling of conventional correlated methods by recasting their working equations into a more compact orbital basis. There are three popular types of orbital representations: local molecular orbitals (LMOs), natural orbitals (NOs) and atomic orbitals. In the LMO basis, the number of significant electron pairs scales quadratically with system size $N$, and a compact virtual molecular space can be constructed for each individual pair whose size is independent of $N$. Natural orbital methods generate a set of compact molecular orbitals from an approximate ground density. Atomic orbital approaches exploit the sparsity of the electron integrals and the density matrix in the AO basis to achieve lower scaling by sparse matrix multiplication (Figure \ref{SparseExample}). Even if the scaling can be effectively reduced, the transformation of the electron integrals to the new orbital representation can still be quite expensive. Techniques such as (local) density can help to reduce the prefactor of local correlation methods.

While the local correlation approximation has been relatively successful for computing ground state properties, the extension to excited state methods is relatively new. With the rapid development in the field of photochemistry and spectroscopy, the demand for accurate and efficient excited state methods has been steadily rising. However, popular correlated methods like coupled cluster linear response (CCLR), the algebraic diagrammatic construction (ADC) method or equation-of-motion coupled cluster (EOM-CC) are plagues by the same steep scaling as their ground state analogs. Due to the delocalized nature of certain excitations such as charge transfer states, a simple extension of local correlation methods is non-trivial. In the last decade, many different solutions were proposed, based on LMOs and NOs, with varying degrees of success. However, an approach based on atomic orbitals has not yet been considered.

This thesis proposes a novel approach to the algebraic diagrammatic construction method using atomic orbital intermediates with the local density fitting approximation. The method, named CDD-DF-SOS-ADC(2), second order spin-opposite scaled  algebraic diagrammatic construction method with density fitting and Cholesky decomposed densities, will be explored in detail in terms of scaling, memory footprint and accuracy.

The thesis is divided into two parts, which address the theoretical and computational aspects respectively. Chapter 1 introduces the basic concepts in theoretical chemistry necessary to describe the ground state. Chapter 2 gives an introduction to excited methods. Chapter 3 discusses the concepts of sparsity and locality in quantum chemistry. Chapter 4 and 5 show how these tools can be used to obtain low-scaling ground and excited state methods. The working equations for CDD-DF-SOS-ADC(2) are derived in Chapter 6, and the results are discussed in Chapter 7.

In the second part, Chapter 8 gives a brief introduction on parallel computing with a few concrete examples written in C. Chapter 9 discusses matrix multiplication, storage and tensor contraction, and briefly describes the matrix libraries used in the \mchem{} quantum chemistry program, whose framework is described in more detail in Chapter 10. Finally Chapter 11 gives insight on a few of the more important algorithms, such as the Davidson diagonalization and the incomplete pivoted Cholesky decomposition.    

\begin{figure}
\centering
\includegraphics[scale=0.05]{Pics/fock.pdf}
\caption[Fock matrix of the GC DNA base pair]{Fock matrix of the guanine-cytosine (GC) DNA base pair, using the cc-pVTZ basis set. The HF wave function was computed using Gaussian \cite{Fri2016}. Bright spots indicate a high absolute value of the matrix elements, while dark spots indicate zero or near-zero values (threshold: 1e-8).}
\label{SparseExample}
\end{figure}